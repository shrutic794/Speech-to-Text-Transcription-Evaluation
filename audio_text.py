# -*- coding: utf-8 -*-
"""AUDIO_TEXT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZVqtnmpbjrX2bJoWj1mqcR-7vyn_BUC3
"""

from google.colab import files

# Upload the file
uploaded = files.upload()

# Check the uploaded files
import os
os.listdir()

# Convert the file to WAV format using ffmpeg
!ffmpeg -i "WhatsApp Ptt 2024-08-12 at 6.29.15 PM.wav" "converted.wav"

# Check if the converted file exists
import os
if os.path.exists('converted.wav'):
    print("File conversion successful, 'converted.wav' found.")
else:
    print("File conversion failed, 'converted.wav' not found.")

file_path = 'converted.wav'
preprocess_audio(file_path, 'processed.wav')

import librosa
import soundfile as sf

# Assuming the file was uploaded successfully
file_path = 'WhatsApp Ptt 2024-08-12 at 6.29.15 PM.wav'

def preprocess_audio(input_path, output_path, sr=22050):
    y, sr = librosa.load(input_path, sr=sr)
    sf.write(output_path, y, sr)

# Preprocess the audio
preprocess_audio(file_path, 'processed.wav')

!pip install SpeechRecognition

import speech_recognition as sr

def transcribe_audio(file_path):
    recognizer = sr.Recognizer()
    with sr.AudioFile(file_path) as source:
        audio = recognizer.record(source)
        try:
            return recognizer.recognize_google(audio)
        except sr.UnknownValueError:
            return None

# Example usage
transcription = transcribe_audio('processed.wav')
print(transcription)

import csv

def save_dataset(audio_files, transcriptions, output_csv):
    with open(output_csv, 'w', newline='') as file:
        writer = csv.writer(file)
        writer.writerow(['audio_path', 'transcription'])
        for audio, transcription in zip(audio_files, transcriptions):
            writer.writerow([audio, transcription])

# Example usage
audio_files = ['processed.wav']
transcriptions = [transcription]
save_dataset(audio_files, transcriptions, 'dataset.csv')

import librosa.display
import numpy as np
import matplotlib.pyplot as plt

def extract_features(audio_path):
    y, sr = librosa.load(audio_path, sr=None)
    mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr)
    return mel_spectrogram

# Example usage
mel_spectrogram = extract_features('processed.wav')

!pip install pandas

import pandas as pd
from torch.utils.data import Dataset, DataLoader

class AudioDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return self.data.iloc[idx]

# Example usage
dataset = AudioDataset('dataset.csv')
dataloader = DataLoader(dataset, batch_size=4, shuffle=True)

# Commented out IPython magic to ensure Python compatibility.
# Clone the repository (replace with the actual repository URL)
!git clone https://github.com/ming024/FastSpeech2.git

# Navigate to the directory
# %cd FastSpeech2

# Install the dependencies
!pip install -r requirements.txt

# Install the module
!python setup.py install

!pip install jiwer

from google.colab import files

uploaded = files.upload()

# List the uploaded files
for filename in uploaded.keys():
    print(f"Uploaded file: {filename}")

import speech_recognition as sr
import jiwer

def transcribe_audio(audio_path):
    recognizer = sr.Recognizer()
    with sr.AudioFile(audio_path) as source:
        audio = recognizer.record(source)
    try:
        text = recognizer.recognize_google(audio)
    except sr.UnknownValueError:
        text = "Google Speech Recognition could not understand audio"
    except sr.RequestError:
        text = "Could not request results from Google Speech Recognition service"
    return text

# Use the filename from the upload output
audio_path = "WhatsApp Ptt 2024-08-12 at 6.29.15 PM.wav"

# Transcribe the audio
transcribed_text = transcribe_audio(audio_path)
print(f"Transcribed Text: {transcribed_text}")

# Reference text (correct transcription)
reference_text = "This is Shruti Chandrashekar of ECB"  # Adjust as needed

# Calculate WER
wer = jiwer.wer(reference_text, transcribed_text)
print(f"Word Error Rate (WER): {wer}")